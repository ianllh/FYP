{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import toad\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "from statsmodels.tsa.stattools import ccf\n",
    "import io\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "\n",
    "# Read and prepare data\n",
    "df = pd.read_csv(\"/Users/lokheilee/python/fyp/6. Stepwise/For SEM dataset quarterly.csv\")\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Function to calculate lead-lag relationships with max 2 periods\n",
    "def calculate_lead_lag(data, target_col, max_lags=2):\n",
    "    lead_lag_results = {}\n",
    "    \n",
    "    for column in data.columns:\n",
    "        if column != target_col:\n",
    "            correlations = {}\n",
    "            for lag in range(-max_lags, max_lags + 1):\n",
    "                if lag == 0:\n",
    "                    corr = data[target_col].corr(data[column])\n",
    "                else:\n",
    "                    corr = data[target_col].corr(data[column].shift(lag))\n",
    "                correlations[lag] = corr\n",
    "            \n",
    "            max_corr_lag = max(correlations.items(), key=lambda x: abs(x[1]))[0]\n",
    "            \n",
    "            granger_test = grangercausalitytests(pd.concat([data[target_col], data[column]], axis=1), \n",
    "                                               maxlag=max_lags, verbose=False)\n",
    "            \n",
    "            lead_lag_results[column] = {\n",
    "                'max_correlation_lag': max_corr_lag,\n",
    "                'correlation_value': correlations[max_corr_lag],\n",
    "                'granger_min_pvalue': min(granger_test[i][0]['ssr_chi2test'][1] for i in range(1, max_lags + 1))\n",
    "            }\n",
    "    \n",
    "    return lead_lag_results\n",
    "\n",
    "# Function to create and save model summary visualization\n",
    "def create_model_summary_plot(model, title, filename):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.axis('off')\n",
    "    plt.text(0.1, 0.95, model.summary().as_text(), fontsize=10, family='monospace', verticalalignment='top')\n",
    "    plt.title(title)\n",
    "    plt.savefig(filename, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "target_y = 'Innoviva Inc'\n",
    "target_filename = target_y.replace(' ', '_').replace('/', '_').replace('\\\\', '_')\n",
    "output_dir = f'analysis_results_{target_filename}'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Calculate lead-lag relationships\n",
    "lead_lag_results = calculate_lead_lag(df, target_y, max_lags=2)\n",
    "\n",
    "# Initial model preparation\n",
    "df_analysis = pd.DataFrame()\n",
    "df_analysis[target_y] = df[target_y]\n",
    "used_base_columns = set()\n",
    "\n",
    "for column, results in lead_lag_results.items():\n",
    "    if column in used_base_columns:\n",
    "        continue\n",
    "        \n",
    "    base_column = column.split('_lag_')[0].split('_lead_')[0]\n",
    "    if base_column in used_base_columns:\n",
    "        continue\n",
    "        \n",
    "    lag = results['max_correlation_lag']\n",
    "    p_value = results['granger_min_pvalue']\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        if lag == 0:\n",
    "            df_analysis[column] = df[column]\n",
    "        elif lag > 0:\n",
    "            df_analysis[f'{column}_lag_{lag}'] = df[column].shift(lag)\n",
    "        else:\n",
    "            df_analysis[f'{column}_lead_{abs(lag)}'] = df[column].shift(-lag)\n",
    "    else:\n",
    "        df_analysis[column] = df[column]\n",
    "        \n",
    "    used_base_columns.add(base_column)\n",
    "\n",
    "df_analysis = df_analysis.fillna(0)\n",
    "\n",
    "# Iterative model refinement\n",
    "iteration = 1\n",
    "current_data = df_analysis.copy()\n",
    "\n",
    "while True:\n",
    "    # Perform stepwise regression\n",
    "    both_aic_data = toad.selection.stepwise(current_data,\n",
    "                                          target=target_y,\n",
    "                                          estimator='ols',\n",
    "                                          criterion='aic',\n",
    "                                          direction='both')\n",
    "    \n",
    "    both_aic_data = both_aic_data[[target_y] + \n",
    "        [col for col in both_aic_data.columns if col != target_y]]\n",
    "    \n",
    "    # Fit model\n",
    "    y = both_aic_data.iloc[:, 0]\n",
    "    X = both_aic_data.iloc[:, 1:]\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    # Save current iteration summary\n",
    "    create_model_summary_plot(model, \n",
    "                            f'Model Summary - Iteration {iteration}',\n",
    "                            os.path.join(output_dir, f'{target_filename}_model_summary_iteration_{iteration}.png'))\n",
    "    \n",
    "    # Check p-values\n",
    "    p_values = model.pvalues[1:]  # Exclude constant\n",
    "    max_p_value = p_values.max()\n",
    "    \n",
    "    if max_p_value <= 0.05:\n",
    "        print(f\"\\nAll p-values are below 0.05 after {iteration} iterations.\")\n",
    "        final_model = model\n",
    "        break\n",
    "    \n",
    "    # Remove variable with highest p-value\n",
    "    var_to_remove = p_values.idxmax()\n",
    "    current_data = current_data.drop(columns=[var_to_remove])\n",
    "    print(f\"\\nIteration {iteration}: Removed {var_to_remove} (p-value: {max_p_value:.4f})\")\n",
    "    \n",
    "    iteration += 1\n",
    "\n",
    "# Save final visualizations\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(both_aic_data.corr(), annot=True, cmap='coolwarm', center=0)\n",
    "plt.title(f'Final Correlation Heatmap - {target_y}')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, f'{target_filename}_final_correlation_heatmap.png'), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Model performance visualization\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title(f'Original vs Predicted Values - {target_y}')\n",
    "plt.plot(y, label='Actual')\n",
    "plt.plot(final_model.fittedvalues, label='Predicted')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Residuals')\n",
    "plt.plot(final_model.resid)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, f'{target_filename}_final_model_visualization.png'), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Save final results to text file\n",
    "with open(os.path.join(output_dir, f'{target_filename}_final_analysis_results.txt'), 'w') as f:\n",
    "    f.write(f\"Final Analysis Results for {target_y}\\n\")\n",
    "    f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "    f.write(f\"Number of iterations required: {iteration}\\n\\n\")\n",
    "    f.write(\"Final Model Summary:\\n\")\n",
    "    f.write(final_model.summary().as_text())\n",
    "    f.write(\"\\n\\nFinal Variables:\\n\")\n",
    "    for var in X.columns[1:]:  # Skip constant\n",
    "        f.write(f\"{var}: p-value = {final_model.pvalues[var]:.4f}\\n\")\n",
    "\n",
    "print(f\"\\nFinal analysis results have been saved in directory: {output_dir}\")\n",
    "print(f\"Files saved:\")\n",
    "print(f\"1. Model summary for each iteration (PNG files)\")\n",
    "print(f\"2. {target_filename}_final_correlation_heatmap.png\")\n",
    "print(f\"3. {target_filename}_final_model_visualization.png\")\n",
    "print(f\"4. {target_filename}_final_analysis_results.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
